{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GAkRP51jN2ON"
      },
      "source": [
        "# Environment Setup\n",
        "This file is intended to be run using a GPU with Google Colab. Go through each step and read the comments to learn how to set up parameters, preprocess/download the dataset, and train a model. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zze6IoemxXix",
        "outputId": "bbc4985c-38ee-424d-9833-b89f3ccfc6b9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Tue Nov 18 22:17:07 2025       \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 550.54.15              Driver Version: 550.54.15      CUDA Version: 12.4     |\n",
            "|-----------------------------------------+------------------------+----------------------+\n",
            "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
            "|                                         |                        |               MIG M. |\n",
            "|=========================================+========================+======================|\n",
            "|   0  NVIDIA L4                      Off |   00000000:00:03.0 Off |                    0 |\n",
            "| N/A   46C    P8             12W /   72W |       0MiB /  23034MiB |      0%      Default |\n",
            "|                                         |                        |                  N/A |\n",
            "+-----------------------------------------+------------------------+----------------------+\n",
            "                                                                                         \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| Processes:                                                                              |\n",
            "|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n",
            "|        ID   ID                                                               Usage      |\n",
            "|=========================================================================================|\n",
            "|  No running processes found                                                             |\n",
            "+-----------------------------------------------------------------------------------------+\n"
          ]
        }
      ],
      "source": [
        "# ensure GPU is being used\n",
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NtZhHB27xc31",
        "outputId": "03b3dd6e-c7fd-446d-9419-0b5179f75edf"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "# mount Google Drive with nuScenes dataset .tgz file\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FnGwGze1zi8J",
        "outputId": "f0253c2b-c129-48cb-8dae-5c1593e6e77a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Python 3.12.12\n",
            "torch==2.8.0+cu126\n",
            "torchao==0.10.0\n",
            "torchaudio==2.8.0+cu126\n",
            "torchdata==0.11.0\n",
            "torchsummary==1.5.1\n",
            "torchtune==0.6.1\n",
            "torchvision==0.23.0+cu126\n"
          ]
        }
      ],
      "source": [
        "# system information should be (approx):\n",
        "# Python 3.12.11\n",
        "# torch>=2.8.0\n",
        "# torchvision>=0.23.0\n",
        "# If there are issues, consider changing your runtime version to match the python version\n",
        "!python3 --version\n",
        "!pip freeze | grep torch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j9Fqkxcix8HW",
        "outputId": "7bdf35e4-fbbc-4e9f-d6a2-5b729351d097"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/content\n",
            "Cloning /content/CenterFusionModern\n",
            "Cloning into 'CenterFusionModern'...\n",
            "remote: Enumerating objects: 303, done.\u001b[K\n",
            "remote: Counting objects: 100% (303/303), done.\u001b[K\n",
            "remote: Compressing objects: 100% (200/200), done.\u001b[K\n",
            "remote: Total 303 (delta 174), reused 215 (delta 93), pack-reused 0 (from 0)\u001b[K\n",
            "Receiving objects: 100% (303/303), 117.11 KiB | 11.71 MiB/s, done.\n",
            "Resolving deltas: 100% (174/174), done.\n",
            "Initializing submodules\n",
            "/content/CenterFusionModern\n",
            "Submodule 'src/tools/nuscenes-devkit' (https://github.com/nutonomy/nuscenes-devkit) registered for path 'src/tools/nuscenes-devkit'\n",
            "Cloning into '/content/CenterFusionModern/src/tools/nuscenes-devkit'...\n",
            "Submodule path 'src/tools/nuscenes-devkit': checked out 'd9de17a73bdc06ce97a02f77ae7edb9b0406e851'\n",
            "/content\n"
          ]
        }
      ],
      "source": [
        "# clone or pull the CenterFusionModern repository\n",
        "import os\n",
        "CF_ROOT = \"/content/CenterFusionModern\"\n",
        "%cd /content/\n",
        "repo_url = \"https://github.com/mattbriggs04/CenterFusionModern.git\"\n",
        "init_submodules = False\n",
        "if not os.path.exists(CF_ROOT):\n",
        "  print(f\"Cloning {CF_ROOT}\")\n",
        "  !git clone {repo_url}\n",
        "  init_submodules = True\n",
        "else:\n",
        "  print(f\"Updating {CF_ROOT}\")\n",
        "  %cd {CF_ROOT}\n",
        "  !git pull -f origin main\n",
        "  %cd ..\n",
        "\n",
        "if init_submodules:\n",
        "  print(f\"Initializing submodules\")\n",
        "  %cd {CF_ROOT}\n",
        "  !git submodule update --init --recursive\n",
        "  %cd .."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "w0ivGS5ZusZk",
        "outputId": "0c97b248-d489-455d-d10e-571683739592"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/content/CenterFusionModern\n",
            "Requirement already satisfied: cachetools in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 1)) (5.5.2)\n",
            "Requirement already satisfied: contourpy in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 2)) (1.3.3)\n",
            "Requirement already satisfied: cycler in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 3)) (0.12.1)\n",
            "Requirement already satisfied: Cython in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 4)) (3.0.12)\n",
            "Collecting descartes (from -r requirements.txt (line 5))\n",
            "  Downloading descartes-1.1.0-py3-none-any.whl.metadata (2.4 kB)\n",
            "Requirement already satisfied: easydict in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 6)) (1.13)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 7)) (3.20.0)\n",
            "Collecting fire (from -r requirements.txt (line 8))\n",
            "  Downloading fire-0.7.1-py3-none-any.whl.metadata (5.8 kB)\n",
            "Requirement already satisfied: fonttools in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 9)) (4.60.1)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 10)) (2025.3.0)\n",
            "Requirement already satisfied: Jinja2 in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 11)) (3.1.6)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 12)) (1.5.2)\n",
            "Requirement already satisfied: kiwisolver in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 13)) (1.4.9)\n",
            "Requirement already satisfied: llvmlite in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 14)) (0.43.0)\n",
            "Requirement already satisfied: MarkupSafe in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 15)) (3.0.3)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 16)) (3.10.0)\n",
            "Requirement already satisfied: mpmath in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 17)) (1.3.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 18)) (3.5)\n",
            "Collecting numpy<2.0.0,>=1.25.0 (from -r requirements.txt (line 19))\n",
            "  Downloading numpy-1.26.4-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (61 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.0/61.0 kB\u001b[0m \u001b[31m6.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nuscenes-devkit (from -r requirements.txt (line 20))\n",
            "  Downloading nuscenes_devkit-1.2.0-py3-none-any.whl.metadata (16 kB)\n",
            "Collecting opencv-python<=4.9.0.80 (from -r requirements.txt (line 21))\n",
            "  Downloading opencv_python-4.9.0.80-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (20 kB)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 22)) (25.0)\n",
            "Collecting parameterized (from -r requirements.txt (line 23))\n",
            "  Downloading parameterized-0.9.0-py2.py3-none-any.whl.metadata (18 kB)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 24)) (11.3.0)\n",
            "Collecting progress (from -r requirements.txt (line 25))\n",
            "  Downloading progress-1.6.1-py3-none-any.whl.metadata (4.3 kB)\n",
            "Requirement already satisfied: pycocotools in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 26)) (2.0.10)\n",
            "Requirement already satisfied: pyparsing in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 27)) (3.2.5)\n",
            "Collecting pyquaternion (from -r requirements.txt (line 28))\n",
            "  Downloading pyquaternion-0.9.9-py3-none-any.whl.metadata (1.4 kB)\n",
            "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 29)) (2.9.0.post0)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 30)) (6.0.3)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 31)) (1.6.1)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 32)) (1.16.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 33)) (75.2.0)\n",
            "Requirement already satisfied: shapely in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 34)) (2.1.2)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 35)) (1.17.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 36)) (1.13.3)\n",
            "Requirement already satisfied: termcolor in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 37)) (3.2.0)\n",
            "Requirement already satisfied: threadpoolctl in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 38)) (3.6.0)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 39)) (2.8.0+cu126)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 40)) (0.23.0+cu126)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 41)) (4.67.1)\n",
            "Requirement already satisfied: typing_extensions in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 42)) (4.15.0)\n",
            "Requirement already satisfied: opencv-python-headless>=4.5.4.58 in /usr/local/lib/python3.12/dist-packages (from nuscenes-devkit->-r requirements.txt (line 20)) (4.12.0.88)\n",
            "Collecting shapely (from -r requirements.txt (line 34))\n",
            "  Downloading shapely-2.0.7-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.8 kB)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch->-r requirements.txt (line 39)) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch->-r requirements.txt (line 39)) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch->-r requirements.txt (line 39)) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch->-r requirements.txt (line 39)) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch->-r requirements.txt (line 39)) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch->-r requirements.txt (line 39)) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch->-r requirements.txt (line 39)) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch->-r requirements.txt (line 39)) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch->-r requirements.txt (line 39)) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch->-r requirements.txt (line 39)) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.3 in /usr/local/lib/python3.12/dist-packages (from torch->-r requirements.txt (line 39)) (2.27.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch->-r requirements.txt (line 39)) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch->-r requirements.txt (line 39)) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch->-r requirements.txt (line 39)) (1.11.1.6)\n",
            "Requirement already satisfied: triton==3.4.0 in /usr/local/lib/python3.12/dist-packages (from torch->-r requirements.txt (line 39)) (3.4.0)\n",
            "INFO: pip is looking at multiple versions of opencv-python-headless to determine which version is compatible with other requirements. This could take a while.\n",
            "Collecting opencv-python-headless>=4.5.4.58 (from nuscenes-devkit->-r requirements.txt (line 20))\n",
            "  Downloading opencv_python_headless-4.11.0.86-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (20 kB)\n",
            "Downloading descartes-1.1.0-py3-none-any.whl (5.8 kB)\n",
            "Downloading fire-0.7.1-py3-none-any.whl (115 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m115.9/115.9 kB\u001b[0m \u001b[31m13.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading numpy-1.26.4-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (18.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m18.0/18.0 MB\u001b[0m \u001b[31m135.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nuscenes_devkit-1.2.0-py3-none-any.whl (315 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m316.0/316.0 kB\u001b[0m \u001b[31m28.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading opencv_python-4.9.0.80-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (62.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.2/62.2 MB\u001b[0m \u001b[31m43.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading parameterized-0.9.0-py2.py3-none-any.whl (20 kB)\n",
            "Downloading progress-1.6.1-py3-none-any.whl (9.8 kB)\n",
            "Downloading pyquaternion-0.9.9-py3-none-any.whl (14 kB)\n",
            "Downloading shapely-2.0.7-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m90.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading opencv_python_headless-4.11.0.86-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (50.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.0/50.0 MB\u001b[0m \u001b[31m54.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: progress, parameterized, numpy, fire, shapely, pyquaternion, opencv-python-headless, opencv-python, descartes, nuscenes-devkit\n",
            "  Attempting uninstall: numpy\n",
            "    Found existing installation: numpy 2.0.2\n",
            "    Uninstalling numpy-2.0.2:\n",
            "      Successfully uninstalled numpy-2.0.2\n",
            "  Attempting uninstall: shapely\n",
            "    Found existing installation: shapely 2.1.2\n",
            "    Uninstalling shapely-2.1.2:\n",
            "      Successfully uninstalled shapely-2.1.2\n",
            "  Attempting uninstall: opencv-python-headless\n",
            "    Found existing installation: opencv-python-headless 4.12.0.88\n",
            "    Uninstalling opencv-python-headless-4.12.0.88:\n",
            "      Successfully uninstalled opencv-python-headless-4.12.0.88\n",
            "  Attempting uninstall: opencv-python\n",
            "    Found existing installation: opencv-python 4.12.0.88\n",
            "    Uninstalling opencv-python-4.12.0.88:\n",
            "      Successfully uninstalled opencv-python-4.12.0.88\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "opencv-contrib-python 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 1.26.4 which is incompatible.\n",
            "pytensor 2.35.1 requires numpy>=2.0, but you have numpy 1.26.4 which is incompatible.\n",
            "jax 0.7.2 requires numpy>=2.0, but you have numpy 1.26.4 which is incompatible.\n",
            "shap 0.50.0 requires numpy>=2, but you have numpy 1.26.4 which is incompatible.\n",
            "jaxlib 0.7.2 requires numpy>=2.0, but you have numpy 1.26.4 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed descartes-1.1.0 fire-0.7.1 numpy-1.26.4 nuscenes-devkit-1.2.0 opencv-python-4.9.0.80 opencv-python-headless-4.11.0.86 parameterized-0.9.0 progress-1.6.1 pyquaternion-0.9.9 shapely-2.0.7\n"
          ]
        },
        {
          "data": {
            "application/vnd.colab-display-data+json": {
              "id": "0d022d5623b148f9b7e9a2923126e0a5",
              "pip_warning": {
                "packages": [
                  "numpy"
                ]
              }
            }
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# pip install requirements\n",
        "# Colab may ask you to restart the session, after restarting run all blocks above\n",
        "# and this block again to ensure there is no errors\n",
        "%cd CenterFusionModern\n",
        "!pip install -r requirements.txt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cf5P3FW6N8xp"
      },
      "source": [
        "# Data Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-FIiBMmzxmMj",
        "outputId": "9b3aa9b9-e797-48c9-95cc-4371ae6e799e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Copying dataset from Google Drive to Colab runtime (this will take a minute)...\n",
            "Copy complete.\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "dataset_path = \"/content/drive/MyDrive/nuScenes/v1.0-mini.tgz\"\n",
        "dest_path = \"/content/CenterFusionModern/data/\"\n",
        "\n",
        "# make a new directory if it does not already exist\n",
        "# it should -- ensure CenterFusionModern is cloned\n",
        "if not os.path.exists(dest_path):\n",
        "  !mkdir -p f\"{dest_path}\"\n",
        "\n",
        "# copy the compressed file\n",
        "print(\"Copying dataset from Google Drive to Colab runtime (this will take a minute)...\")\n",
        "!cp \"{dataset_path}\" \"{dest_path}\"\n",
        "print(\"Copy complete.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5tp5jehjNUVF",
        "outputId": "2b23e11d-2d8b-4572-acda-a6132a6ec580"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Unzipping the dataset (this will take a minute)...\n",
            "Unzipping complete.\n"
          ]
        }
      ],
      "source": [
        "# unzip the file\n",
        "print(\"Unzipping the dataset (this will take a minute)...\")\n",
        "!mkdir -p \"{dest_path}/nuscenes/\"\n",
        "!tar -xzf \"{dest_path}/v1.0-mini.tgz\" -C \"{dest_path}/nuscenes/\"\n",
        "print(\"Unzipping complete.\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-kkTFdnIPAhC"
      },
      "outputs": [],
      "source": [
        "# clean up the copied .tgz file (optional)\n",
        "!rm \"{dest_path}/v1.0-mini.tgz\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5FMpFh9vNv3f"
      },
      "source": [
        "# Camera-Radar Fusion Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xih_q-C-VI7S",
        "outputId": "ceabe527-01d8-41ad-e8da-03548b7f62f5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Using mini nuScenes dataset only\n",
            "Either no command line arguments given or they're invalid.\n",
            "Using NUM_SWEEPS = 6\n",
            "======\n",
            "Loading NuScenes tables for version v1.0-mini...\n",
            "23 category,\n",
            "8 attribute,\n",
            "4 visibility,\n",
            "911 instance,\n",
            "12 sensor,\n",
            "120 calibrated_sensor,\n",
            "31206 ego_pose,\n",
            "8 log,\n",
            "10 scene,\n",
            "404 sample,\n",
            "31206 sample_data,\n",
            "18538 sample_annotation,\n",
            "4 map,\n",
            "Done loading in 0.381 seconds.\n",
            "======\n",
            "Reverse indexing ...\n",
            "Done reverse indexing in 0.1 seconds.\n",
            "======\n",
            "scene_name scene-0103\n",
            "scene_name scene-0916\n",
            "reordering images\n",
            "mini_val 486 images 4910 boxes\n",
            "out_path ../data/nuscenes/annotations_6sweeps/mini_val.json\n",
            "======\n",
            "Loading NuScenes tables for version v1.0-mini...\n",
            "23 category,\n",
            "8 attribute,\n",
            "4 visibility,\n",
            "911 instance,\n",
            "12 sensor,\n",
            "120 calibrated_sensor,\n",
            "31206 ego_pose,\n",
            "8 log,\n",
            "10 scene,\n",
            "404 sample,\n",
            "31206 sample_data,\n",
            "18538 sample_annotation,\n",
            "4 map,\n",
            "Done loading in 0.372 seconds.\n",
            "======\n",
            "Reverse indexing ...\n",
            "Done reverse indexing in 0.1 seconds.\n",
            "======\n",
            "scene_name scene-0061\n",
            "scene_name scene-0553\n",
            "scene_name scene-0655\n",
            "scene_name scene-0757\n",
            "scene_name scene-0796\n",
            "scene_name scene-1077\n",
            "scene_name scene-1094\n",
            "scene_name scene-1100\n",
            "reordering images\n",
            "mini_train 1938 images 14694 boxes\n",
            "out_path ../data/nuscenes/annotations_6sweeps/mini_train.json\n"
          ]
        }
      ],
      "source": [
        "# convert nuScenes dataset (6 radar sweeps)\n",
        "!cd \"{CF_ROOT}/src\" && \\\n",
        "python3 convert_nuScenes.py"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RiNda6F-NOzX"
      },
      "outputs": [],
      "source": [
        "# define useful parameters to be used between cells\n",
        "# this is helpful if we are only testing a model, only training, only visualizing\n",
        "# or any combination -- consistency is key\n",
        "\n",
        "# number of epochs to train model\n",
        "# if resuming, this should be the total number of epochs you want to train to\n",
        "NUM_EPOCHS = 20\n",
        "\n",
        "# model save paths\n",
        "MODEL_SAVE_NAME = f\"model_{NUM_EPOCHS}.pth\" # this is how the script will name the model by default, even if resuming\n",
        "MODEL_SAVE_PATH = f\"{CF_ROOT}/exp/ddd/centerfusion/{MODEL_SAVE_NAME}\"\n",
        "DRIVE_CF_DIR_PATH = \"/content/drive/MyDrive/CenterFusionModern\"\n",
        "\n",
        "# model load path, this is the path to the model you are evaluating\n",
        "# will also resume from model load path\n",
        "MODEL_LOAD_PATH = MODEL_SAVE_PATH\n",
        "RESUME_TRAINING = True\n",
        "if RESUME_TRAINING:\n",
        "    MODEL_LOAD_PATH = f\"{DRIVE_CF_DIR_PATH}/fusion_e20.pth\"\n",
        "\n",
        "# scale up the defaults to utilize the A100 at max potential\n",
        "# learning rate should scale with batch size\n",
        "BATCH_SIZE = 8 * 4\n",
        "LEARNING_RATE = 2.5e-4 * 4\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JD-HIAyTSrJv",
        "outputId": "2bfe8601-7d98-4bb9-d278-e5fc390ef93f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "DCN not currently available. Ensure --dla_node 'conv' is being used.\n",
            "Fix size testing.\n",
            "training chunk_sizes: [32]\n",
            "input h w: 448 800\n",
            "heads {'hm': 10, 'reg': 2, 'wh': 2, 'dep': 1, 'rot': 8, 'dim': 3, 'amodel_offset': 2, 'dep_sec': 1, 'rot_sec': 8, 'nuscenes_att': 8, 'velocity': 3}\n",
            "weights {'hm': 1, 'reg': 1, 'wh': 0.1, 'dep': 1, 'rot': 1, 'dim': 1, 'amodel_offset': 1, 'dep_sec': 1, 'rot_sec': 1, 'nuscenes_att': 1, 'velocity': 1}\n",
            "head conv {'hm': [256], 'reg': [256], 'wh': [256], 'dep': [256], 'rot': [256], 'dim': [256], 'amodel_offset': [256], 'dep_sec': [256, 256, 256], 'rot_sec': [256, 256, 256], 'nuscenes_att': [256, 256, 256], 'velocity': [256, 256, 256]}\n",
            "Options = Namespace(task='ddd', dataset='nuscenes', test_dataset='nuscenes', exp_id='centerfusion', eval=False, debug=0, no_pause=False, demo='', load_model='/content/drive/MyDrive/CenterFusionModern/fusion_e10.pth', resume=True, gpus=[0], num_workers=4, not_cuda_benchmark=False, seed=317, not_set_cuda_env=False, print_iter=0, save_all=False, vis_thresh=0.3, debugger_theme='white', run_dataset_eval=False, save_imgs=[], save_img_suffix='', skip_first=-1, save_video=False, save_framerate=30, resize_video=False, video_h=512, video_w=512, transpose_video=False, show_track_color=False, not_show_bbox=False, not_show_number=False, qualitative=False, tango_color=False, arch='dla_34', dla_node='conv', head_conv={'hm': [256], 'reg': [256], 'wh': [256], 'dep': [256], 'rot': [256], 'dim': [256], 'amodel_offset': [256], 'dep_sec': [256, 256, 256], 'rot_sec': [256, 256, 256], 'nuscenes_att': [256, 256, 256], 'velocity': [256, 256, 256]}, num_head_conv=1, head_kernel=3, down_ratio=4, num_classes=10, num_resnet_layers=101, backbone='dla34', neck='dlaup', msra_outchannel=256, prior_bias=-4.6, input_res=800, input_h=448, input_w=800, dataset_version='', optim='adam', lr=0.001, lr_step=[50], save_point=[10, 20], num_epochs=20, batch_size=32, master_batch_size=32, num_iters=-1, val_intervals=5, trainval=False, ltrb=False, ltrb_weight=0.1, reset_hm=False, reuse_hm=False, dense_reg=1, shuffle_train=True, flip_test=False, test_scales=[1.0], nms=False, K=100, not_prefetch_test=False, fix_short=-1, keep_res=False, out_thresh=-1, depth_scale=1, save_results=False, load_results='', use_loaded_results=False, ignore_loaded_cats=[], model_output_list=False, non_block_test=False, vis_gt_bev='', kitti_split='3dop', test_focal_length=-1, not_rand_crop=True, not_max_crop=False, shift=0.1, scale=0, aug_rot=0, rotate=0, flip=0.5, no_color_aug=False, tracking=False, pre_hm=False, same_aug_pre=False, zero_pre_hm=False, hm_disturb=0, lost_disturb=0, fp_disturb=0, pre_thresh=-1, track_thresh=0.3, new_thresh=0.3, max_frame_dist=3, ltrb_amodal=False, ltrb_amodal_weight=0.1, public_det=False, no_pre_img=False, zero_tracking=False, hungarian=False, max_age=-1, tracking_weight=1, reg_loss='l1', hm_weight=1, off_weight=1, wh_weight=0.1, hp_weight=1, hm_hp_weight=1, amodel_offset_weight=1, dep_weight=1, dep_res_weight=1, dim_weight=1, rot_weight=1, nuscenes_att=True, nuscenes_att_weight=1, velocity=True, velocity_weight=1, custom_dataset_img_path='', custom_dataset_ann_path='', pointcloud=True, train_split='mini_train', val_split='mini_val', max_pc=1000, r_a=250, r_b=5, img_format='jpg', max_pc_dist=60.0, freeze_backbone=False, radar_sweeps=6, warm_start_weights=False, pc_z_offset=0.0, eval_n_plots=0, eval_render_curves=False, hm_transparency=0.7, iou_thresh=0, pillar_dims=[1.5, 0.2, 0.2], show_velocity=False, gpus_str='0', pre_img=False, fix_res=True, pad=31, num_stacks=1, chunk_sizes=[32], root_dir='/content/CenterFusionModern/src/lib/../..', data_dir='/content/CenterFusionModern/src/lib/../../data', exp_dir='/content/CenterFusionModern/src/lib/../../exp/ddd', save_dir='/content/CenterFusionModern/src/lib/../../exp/ddd/centerfusion', debug_dir='/content/CenterFusionModern/src/lib/../../exp/ddd/centerfusion/debug', pc_atts=['x', 'y', 'z', 'dyn_prop', 'id', 'rcs', 'vx', 'vy', 'vx_comp', 'vy_comp', 'is_quality_valid', 'ambig_state', 'x_rms', 'y_rms', 'invalid_state', 'pdh0', 'vx_rms', 'vy_rms'], num_img_channels=3, hm_dist_thresh={0: 0, 1: 0, 2: 0, 3: 0, 4: 0, 5: 1, 6: 1, 7: 1, 8: 0, 9: 0}, sigmoid_dep_sec=True, hm_to_box_ratio=0.3, secondary_heads=['velocity', 'nuscenes_att', 'dep_sec', 'rot_sec'], custom_head_convs={'dep_sec': 3, 'rot_sec': 3, 'velocity': 3, 'nuscenes_att': 3}, normalize_depth=True, disable_frustum=False, layers_to_freeze=['base', 'dla_up', 'ida_up'], pc_roi_method='pillars', pc_feat_lvl=['pc_dep', 'pc_vx', 'pc_vz'], frustumExpansionRatio=0.0, sort_det_by_dist=False, pc_feat_channels={'pc_dep': 0, 'pc_vx': 1, 'pc_vz': 2}, output_h=112, output_w=200, output_res=200, heads={'hm': 10, 'reg': 2, 'wh': 2, 'dep': 1, 'rot': 8, 'dim': 3, 'amodel_offset': 2, 'dep_sec': 1, 'rot_sec': 8, 'nuscenes_att': 8, 'velocity': 3}, weights={'hm': 1, 'reg': 1, 'wh': 0.1, 'dep': 1, 'rot': 1, 'dim': 1, 'amodel_offset': 1, 'dep_sec': 1, 'rot_sec': 1, 'nuscenes_att': 1, 'velocity': 1})\n",
            "Loading model /content/drive/MyDrive/CenterFusionModern/fusion_e10.pth...\n",
            "Using node type: (<class 'lib.model.networks.dla.Conv'>, <class 'lib.model.networks.dla.Conv'>)\n",
            "Warning: No ImageNet pretrain!!\n",
            "loaded /content/drive/MyDrive/CenterFusionModern/fusion_e10.pth, epoch 10\n",
            "Drop parameter base.fc.weight.\n",
            "Drop parameter base.fc.bias.\n",
            "Resumed optimizer with start lr 0.001\n",
            "Setting up validation data...\n",
            "Dataset version \n",
            "==> initializing mini_val data from /content/CenterFusionModern/src/lib/../../data/nuscenes/annotations_6sweeps/mini_val.json, \n",
            " images from /content/CenterFusionModern/src/lib/../../data/nuscenes ...\n",
            "loading annotations into memory...\n",
            "Done (t=1.10s)\n",
            "creating index...\n",
            "index created!\n",
            "Loaded mini_val 486 samples\n",
            "Setting up train data...\n",
            "Dataset version \n",
            "==> initializing mini_train data from /content/CenterFusionModern/src/lib/../../data/nuscenes/annotations_6sweeps/mini_train.json, \n",
            " images from /content/CenterFusionModern/src/lib/../../data/nuscenes ...\n",
            "loading annotations into memory...\n",
            "Done (t=4.18s)\n",
            "creating index...\n",
            "index created!\n",
            "Loaded mini_train 1938 samples\n",
            "Starting training...\n",
            "ddd/centerfusion |################################| train: [11][59/60]|Tot: 0:00:48 |ETA: 0:00:01 |tot 34.2536 |hm 3.1434 |wh 8.0243 |reg 0.2520 |dep 10.5807 |dep_sec 11.4142 |dim 0.8546 |rot 1.9734 |rot_sec 1.8270 |amodel_offset 2.3361 |nuscenes_att 0.4464 |velocity 0.6233 |Data 0.330s(0.367s) |Net 0.800s\n",
            "ddd/centerfusion |################################| train: [12][59/60]|Tot: 0:00:35 |ETA: 0:00:01 |tot 27.5962 |hm 2.7811 |wh 7.0561 |reg 0.2479 |dep 7.9341 |dep_sec 8.1487 |dim 0.7262 |rot 1.9301 |rot_sec 1.7899 |amodel_offset 2.2841 |nuscenes_att 0.4211 |velocity 0.6274 |Data 0.330s(0.359s) |Net 0.596s\n",
            "ddd/centerfusion |################################| train: [13][59/60]|Tot: 0:00:35 |ETA: 0:00:01 |tot 24.8267 |hm 2.5839 |wh 6.5155 |reg 0.2467 |dep 6.7938 |dep_sec 6.9455 |dim 0.6614 |rot 1.8982 |rot_sec 1.7536 |amodel_offset 2.2445 |nuscenes_att 0.4230 |velocity 0.6246 |Data 0.324s(0.355s) |Net 0.592s\n",
            "ddd/centerfusion |################################| train: [14][59/60]|Tot: 0:00:35 |ETA: 0:00:01 |tot 24.1139 |hm 2.4517 |wh 6.3804 |reg 0.2470 |dep 6.5373 |dep_sec 6.7879 |dim 0.6337 |rot 1.8625 |rot_sec 1.7194 |amodel_offset 2.2092 |nuscenes_att 0.4079 |velocity 0.6193 |Data 0.328s(0.360s) |Net 0.598s\n",
            "ddd/centerfusion |################################| train: [15][59/60]|Tot: 0:00:36 |ETA: 0:00:01 |tot 23.1953 |hm 2.3878 |wh 6.0085 |reg 0.2468 |dep 6.1549 |dep_sec 6.4044 |dim 0.6122 |rot 1.8404 |rot_sec 1.7006 |amodel_offset 2.2250 |nuscenes_att 0.4042 |velocity 0.6182 |Data 0.329s(0.374s) |Net 0.610s\n",
            "ddd/centerfusion |################################| val: [15][485/486]|Tot: 0:01:49 |ETA: 0:00:01 |tot 29.2822 |hm 3.0885 |wh 9.5909 |reg 0.2432 |dep 7.4728 |dep_sec 9.2274 |dim 0.5962 |rot 1.9516 |rot_sec 1.9564 |amodel_offset 2.9503 |nuscenes_att 0.5717 |velocity 0.2651 |Data 0.001s(0.001s) |Net 0.225s \n",
            "ddd/centerfusion |################################| train: [16][59/60]|Tot: 0:00:36 |ETA: 0:00:01 |tot 22.3063 |hm 2.3420 |wh 5.8580 |reg 0.2486 |dep 5.8654 |dep_sec 6.0331 |dim 0.5916 |rot 1.7964 |rot_sec 1.6468 |amodel_offset 2.1765 |nuscenes_att 0.3925 |velocity 0.6277 |Data 0.329s(0.363s) |Net 0.601s\n",
            "ddd/centerfusion |################################| train: [17][59/60]|Tot: 0:00:36 |ETA: 0:00:01 |tot 24.3435 |hm 2.3414 |wh 5.8506 |reg 0.2477 |dep 6.6939 |dep_sec 7.2065 |dim 0.5899 |rot 1.8099 |rot_sec 1.6761 |amodel_offset 2.1916 |nuscenes_att 0.3926 |velocity 0.6090 |Data 0.327s(0.367s) |Net 0.605s\n",
            "ddd/centerfusion |################################| train: [18][59/60]|Tot: 0:00:36 |ETA: 0:00:01 |tot 22.9771 |hm 2.4085 |wh 6.0136 |reg 0.2472 |dep 6.1308 |dep_sec 6.1772 |dim 0.5968 |rot 1.8114 |rot_sec 1.6771 |amodel_offset 2.3119 |nuscenes_att 0.3974 |velocity 0.6174 |Data 0.329s(0.363s) |Net 0.602s\n",
            "ddd/centerfusion |################################| train: [19][59/60]|Tot: 0:00:36 |ETA: 0:00:01 |tot 22.5189 |hm 2.3329 |wh 5.5806 |reg 0.2469 |dep 5.9876 |dep_sec 6.2708 |dim 0.5616 |rot 1.7683 |rot_sec 1.6157 |amodel_offset 2.1787 |nuscenes_att 0.3875 |velocity 0.6108 |Data 0.328s(0.369s) |Net 0.603s\n",
            "ddd/centerfusion |################################| train: [20][59/60]|Tot: 0:00:35 |ETA: 0:00:01 |tot 21.1725 |hm 2.2433 |wh 5.3420 |reg 0.2455 |dep 5.4802 |dep_sec 5.5819 |dim 0.5508 |rot 1.7361 |rot_sec 1.5959 |amodel_offset 2.2055 |nuscenes_att 0.3813 |velocity 0.6178 |Data 0.330s(0.359s) |Net 0.595s\n",
            "ddd/centerfusion |################################| val: [20][485/486]|Tot: 0:01:55 |ETA: 0:00:01 |tot 22.9574 |hm 2.8468 |wh 8.3479 |reg 0.2408 |dep 5.4772 |dep_sec 5.4748 |dim 0.6186 |rot 1.8746 |rot_sec 1.8793 |amodel_offset 2.9594 |nuscenes_att 0.5017 |velocity 0.2495 |Data 0.001s(0.001s) |Net 0.238s\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "# train fusion model\n",
        "# export CUDA_DEVICE_ORDER=PCI_BUS_ID\n",
        "!export CUDA_VISIBLE_DEVICES=0\n",
        "\n",
        "# train for single gpu\n",
        "if not RESUME_TRAINING:\n",
        "    !cd /content/CenterFusionModern/src && \\\n",
        "    python3 main.py \\\n",
        "        ddd \\\n",
        "        --exp_id centerfusion \\\n",
        "        --arch dla_34 \\\n",
        "        --dla_node 'conv' \\\n",
        "        --shuffle_train \\\n",
        "        --train_split mini_train \\\n",
        "        --val_split mini_val \\\n",
        "        --val_intervals 5 \\\n",
        "        --nuscenes_att \\\n",
        "        --velocity \\\n",
        "        --batch_size {BATCH_SIZE} \\\n",
        "        --lr {LEARNING_RATE} \\\n",
        "        --num_epochs {NUM_EPOCHS} \\\n",
        "        --lr_step 50 \\\n",
        "        --save_point {NUM_EPOCHS // 2},{NUM_EPOCHS} \\\n",
        "        --gpus 0 \\\n",
        "        --not_rand_crop \\\n",
        "        --flip 0.5 \\\n",
        "        --shift 0.1 \\\n",
        "        --pointcloud \\\n",
        "        --radar_sweeps 6 \\\n",
        "        --pc_z_offset 0.0 \\\n",
        "        --pillar_dims 1.0,0.2,0.2 \\\n",
        "        --max_pc_dist 60.0 \\\n",
        "        --print_iter 0 \\\n",
        "        # --run_dataset_eval \\ <-- evaluates dataset with metrics after every validation\n",
        "        # --debug 4 \\ <-- currently broken\n",
        "        # --freeze_backbone \\ <-- use when fine tuning heads\n",
        "\n",
        "\n",
        "# resume training\n",
        "else:\n",
        "    !cd /content/CenterFusionModern/src && \\\n",
        "    python3 main.py \\\n",
        "        ddd \\\n",
        "        --exp_id centerfusion \\\n",
        "        --arch dla_34 \\\n",
        "        --dla_node 'conv' \\\n",
        "        --shuffle_train \\\n",
        "        --train_split mini_train \\\n",
        "        --val_split mini_val \\\n",
        "        --val_intervals 5 \\\n",
        "        --nuscenes_att \\\n",
        "        --velocity \\\n",
        "        --batch_size {BATCH_SIZE} \\\n",
        "        --lr {LEARNING_RATE} \\\n",
        "        --num_epochs {NUM_EPOCHS} \\\n",
        "        --lr_step 50 \\\n",
        "        --save_point {NUM_EPOCHS // 2},{NUM_EPOCHS} \\\n",
        "        --gpus 0 \\\n",
        "        --not_rand_crop \\\n",
        "        --flip 0.5 \\\n",
        "        --shift 0.1 \\\n",
        "        --pointcloud \\\n",
        "        --radar_sweeps 6 \\\n",
        "        --print_iter 0 \\\n",
        "        --pc_z_offset 0.0 \\\n",
        "        --pillar_dims 1.0,0.2,0.2 \\\n",
        "        --max_pc_dist 60.0 \\\n",
        "        --load_model {MODEL_LOAD_PATH} \\\n",
        "        --resume"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AzwkHvJdCn6H",
        "outputId": "4c06da21-391d-442b-daf5-8a9bfd0ee4de"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Copied /content/CenterFusionModern/exp/ddd/centerfusion/model_20.pth to /content/drive/MyDrive/CenterFusionModern successfully.\n"
          ]
        }
      ],
      "source": [
        "# export a copy of fusion model to drive\n",
        "# ensure path is correct, model name is \"model_{numEpochs}\"\n",
        "!cp {MODEL_SAVE_PATH} {DRIVE_CF_DIR_PATH}\n",
        "print(f\"Copied {MODEL_SAVE_PATH} to {DRIVE_CF_DIR_PATH} successfully.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lam7nM--WQIR",
        "outputId": "10fa2e8b-48c4-4eda-aa1b-3561b7a8c8e4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "DCN not currently available. Ensure --dla_node 'conv' is being used.\n",
            "Fix size testing.\n",
            "training chunk_sizes: [32]\n",
            "input h w: 448 800\n",
            "heads {'hm': 10, 'reg': 2, 'wh': 2, 'dep': 1, 'rot': 8, 'dim': 3, 'amodel_offset': 2, 'dep_sec': 1, 'rot_sec': 8, 'nuscenes_att': 8, 'velocity': 3}\n",
            "weights {'hm': 1, 'reg': 1, 'wh': 0.1, 'dep': 1, 'rot': 1, 'dim': 1, 'amodel_offset': 1, 'dep_sec': 1, 'rot_sec': 1, 'nuscenes_att': 1, 'velocity': 1}\n",
            "head conv {'hm': [256], 'reg': [256], 'wh': [256], 'dep': [256], 'rot': [256], 'dim': [256], 'amodel_offset': [256], 'dep_sec': [256, 256, 256], 'rot_sec': [256, 256, 256], 'nuscenes_att': [256, 256, 256], 'velocity': [256, 256, 256]}\n",
            "Namespace(task='ddd', dataset='nuscenes', test_dataset='nuscenes', exp_id='centerfusion', eval=False, debug=0, no_pause=False, demo='', load_model='/content/drive/MyDrive/CenterFusionModern/fusion_e20.pth', resume=False, gpus=[0], num_workers=4, not_cuda_benchmark=False, seed=317, not_set_cuda_env=False, print_iter=0, save_all=False, vis_thresh=0.3, debugger_theme='white', run_dataset_eval=True, save_imgs=[], save_img_suffix='', skip_first=-1, save_video=False, save_framerate=30, resize_video=False, video_h=512, video_w=512, transpose_video=False, show_track_color=False, not_show_bbox=False, not_show_number=False, qualitative=False, tango_color=False, arch='dla_34', dla_node='conv', head_conv={'hm': [256], 'reg': [256], 'wh': [256], 'dep': [256], 'rot': [256], 'dim': [256], 'amodel_offset': [256], 'dep_sec': [256, 256, 256], 'rot_sec': [256, 256, 256], 'nuscenes_att': [256, 256, 256], 'velocity': [256, 256, 256]}, num_head_conv=1, head_kernel=3, down_ratio=4, num_classes=10, num_resnet_layers=101, backbone='dla34', neck='dlaup', msra_outchannel=256, prior_bias=-4.6, input_res=800, input_h=448, input_w=800, dataset_version='', optim='adam', lr=0.000125, lr_step=[60], save_point=[90], num_epochs=70, batch_size=32, master_batch_size=32, num_iters=-1, val_intervals=10, trainval=False, ltrb=False, ltrb_weight=0.1, reset_hm=False, reuse_hm=False, dense_reg=1, shuffle_train=False, flip_test=False, test_scales=[1.0], nms=False, K=100, not_prefetch_test=False, fix_short=-1, keep_res=False, out_thresh=-1, depth_scale=1, save_results=False, load_results='', use_loaded_results=False, ignore_loaded_cats=[], model_output_list=False, non_block_test=False, vis_gt_bev='', kitti_split='3dop', test_focal_length=-1, not_rand_crop=False, not_max_crop=False, shift=0, scale=0, aug_rot=0, rotate=0, flip=0.5, no_color_aug=False, tracking=False, pre_hm=False, same_aug_pre=False, zero_pre_hm=False, hm_disturb=0, lost_disturb=0, fp_disturb=0, pre_thresh=-1, track_thresh=0.3, new_thresh=0.3, max_frame_dist=3, ltrb_amodal=False, ltrb_amodal_weight=0.1, public_det=False, no_pre_img=False, zero_tracking=False, hungarian=False, max_age=-1, tracking_weight=1, reg_loss='l1', hm_weight=1, off_weight=1, wh_weight=0.1, hp_weight=1, hm_hp_weight=1, amodel_offset_weight=1, dep_weight=1, dep_res_weight=1, dim_weight=1, rot_weight=1, nuscenes_att=True, nuscenes_att_weight=1, velocity=True, velocity_weight=1, custom_dataset_img_path='', custom_dataset_ann_path='', pointcloud=True, train_split='train', val_split='mini_val', max_pc=1000, r_a=250, r_b=5, img_format='jpg', max_pc_dist=100.0, freeze_backbone=False, radar_sweeps=6, warm_start_weights=False, pc_z_offset=0, eval_n_plots=0, eval_render_curves=False, hm_transparency=0.7, iou_thresh=0, pillar_dims=[1.5, 0.2, 0.2], show_velocity=False, gpus_str='0', pre_img=False, fix_res=True, pad=31, num_stacks=1, chunk_sizes=[32], root_dir='/content/CenterFusionModern/src/lib/../..', data_dir='/content/CenterFusionModern/src/lib/../../data', exp_dir='/content/CenterFusionModern/src/lib/../../exp/ddd', save_dir='/content/CenterFusionModern/src/lib/../../exp/ddd/centerfusion', debug_dir='/content/CenterFusionModern/src/lib/../../exp/ddd/centerfusion/debug', pc_atts=['x', 'y', 'z', 'dyn_prop', 'id', 'rcs', 'vx', 'vy', 'vx_comp', 'vy_comp', 'is_quality_valid', 'ambig_state', 'x_rms', 'y_rms', 'invalid_state', 'pdh0', 'vx_rms', 'vy_rms'], num_img_channels=3, hm_dist_thresh={0: 0, 1: 0, 2: 0, 3: 0, 4: 0, 5: 1, 6: 1, 7: 1, 8: 0, 9: 0}, sigmoid_dep_sec=True, hm_to_box_ratio=0.3, secondary_heads=['velocity', 'nuscenes_att', 'dep_sec', 'rot_sec'], custom_head_convs={'dep_sec': 3, 'rot_sec': 3, 'velocity': 3, 'nuscenes_att': 3}, normalize_depth=True, disable_frustum=False, layers_to_freeze=['base', 'dla_up', 'ida_up'], pc_roi_method='pillars', pc_feat_lvl=['pc_dep', 'pc_vx', 'pc_vz'], frustumExpansionRatio=0.0, sort_det_by_dist=False, pc_feat_channels={'pc_dep': 0, 'pc_vx': 1, 'pc_vz': 2}, output_h=112, output_w=200, output_res=200, heads={'hm': 10, 'reg': 2, 'wh': 2, 'dep': 1, 'rot': 8, 'dim': 3, 'amodel_offset': 2, 'dep_sec': 1, 'rot_sec': 8, 'nuscenes_att': 8, 'velocity': 3}, weights={'hm': 1, 'reg': 1, 'wh': 0.1, 'dep': 1, 'rot': 1, 'dim': 1, 'amodel_offset': 1, 'dep_sec': 1, 'rot_sec': 1, 'nuscenes_att': 1, 'velocity': 1})\n",
            "Dataset version \n",
            "==> initializing mini_val data from /content/CenterFusionModern/src/lib/../../data/nuscenes/annotations_6sweeps/mini_val.json, \n",
            " images from /content/CenterFusionModern/src/lib/../../data/nuscenes ...\n",
            "loading annotations into memory...\n",
            "Done (t=1.11s)\n",
            "creating index...\n",
            "index created!\n",
            "Loaded mini_val 486 samples\n",
            "Creating model...\n",
            "Using node type: (<class 'lib.model.networks.dla.Conv'>, <class 'lib.model.networks.dla.Conv'>)\n",
            "Warning: No ImageNet pretrain!!\n",
            "loaded /content/drive/MyDrive/CenterFusionModern/fusion_e20.pth, epoch 20\n",
            "centerfusion |################################| [485/486]|Tot: 0:01:49 |ETA: 0:00:01 |tot 0.194s (0.224s) |load 0.000s (0.000s) |pre 0.000s (0.000s) |net 0.180s (0.210s) |dec 0.002s (0.002s) |post 0.011s (0.011s) |merge 0.001s (0.001s) |track 0.000s (0.000s) \n",
            "Converting nuscenes format...\n",
            "======\n",
            "Loading NuScenes tables for version v1.0-mini...\n",
            "23 category,\n",
            "8 attribute,\n",
            "4 visibility,\n",
            "911 instance,\n",
            "12 sensor,\n",
            "120 calibrated_sensor,\n",
            "31206 ego_pose,\n",
            "8 log,\n",
            "10 scene,\n",
            "404 sample,\n",
            "31206 sample_data,\n",
            "18538 sample_annotation,\n",
            "4 map,\n",
            "Done loading in 0.393 seconds.\n",
            "======\n",
            "Reverse indexing ...\n",
            "Done reverse indexing in 0.1 seconds.\n",
            "======\n",
            "Initializing nuScenes detection evaluation\n",
            "Loaded results from /content/CenterFusionModern/src/lib/../../exp/ddd/centerfusion/results_nuscenes_det_mini_val.json. Found detections for 81 samples.\n",
            "Loading annotations for mini_val split from nuScenes version: v1.0-mini\n",
            "100% 81/81 [00:00<00:00, 388.41it/s]\n",
            "Loaded ground truth annotations for 81 samples.\n",
            "Filtering predictions\n",
            "=> Original number of boxes: 40500\n",
            "=> After distance based filtering: 33067\n",
            "=> After LIDAR and RADAR points based filtering: 33067\n",
            "=> After bike rack filtering: 33067\n",
            "Filtering ground truth annotations\n",
            "=> Original number of boxes: 4441\n",
            "=> After distance based filtering: 3785\n",
            "=> After LIDAR and RADAR points based filtering: 3393\n",
            "=> After bike rack filtering: 3393\n",
            "Accumulating metric data...\n",
            "Calculating metrics...\n",
            "Saving metrics to: /content/CenterFusionModern/src/lib/../../exp/ddd/centerfusion/nuscenes_eval_det_output_mini_val/\n",
            "mAP: 0.0242\n",
            "mATE: 1.0251\n",
            "mASE: 0.8246\n",
            "mAOE: 1.0418\n",
            "mAVE: 0.8894\n",
            "mAAE: 0.8294\n",
            "NDS: 0.0578\n",
            "Eval time: 7.7s\n",
            "\n",
            "Per-class results:\n",
            "Object Class        \tAP    \tATE   \tASE   \tAOE   \tAVE   \tAAE   \n",
            "car                 \t0.049 \t1.244 \t0.286 \t1.104 \t0.201 \t0.443 \n",
            "truck               \t0.000 \t1.000 \t1.000 \t1.000 \t1.000 \t1.000 \n",
            "bus                 \t0.000 \t1.000 \t1.000 \t1.000 \t1.000 \t1.000 \n",
            "trailer             \t0.000 \t1.000 \t1.000 \t1.000 \t1.000 \t1.000 \n",
            "construction_vehicle\t0.000 \t1.000 \t1.000 \t1.000 \t1.000 \t1.000 \n",
            "pedestrian          \t0.035 \t1.074 \t0.415 \t1.272 \t0.914 \t0.192 \n",
            "motorcycle          \t0.000 \t1.000 \t1.000 \t1.000 \t1.000 \t1.000 \n",
            "bicycle             \t0.000 \t1.000 \t1.000 \t1.000 \t1.000 \t1.000 \n",
            "traffic_cone        \t0.158 \t0.933 \t0.545 \tnan   \tnan   \tnan   \n",
            "barrier             \t0.000 \t1.000 \t1.000 \t1.000 \tnan   \tnan   \n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "# test model metrics\n",
        "# set the GPU to be visible\n",
        "!export CUDA_VISIBLE_DEVICES=0\n",
        "\n",
        "# Navigate to the source directory\n",
        "# Run the evaluation script\n",
        "!cd /content/CenterFusionModern/src && \\\n",
        "python3 test.py ddd \\\n",
        "    --exp_id centerfusion \\\n",
        "    --arch dla_34 \\\n",
        "    --dla_node 'conv' \\\n",
        "    --dataset nuscenes \\\n",
        "    --nuscenes_att \\\n",
        "    --velocity \\\n",
        "    --val_split mini_val \\\n",
        "    --run_dataset_eval \\\n",
        "    --pointcloud \\\n",
        "    --radar_sweeps 6 \\\n",
        "    --gpus 0 \\\n",
        "    --load_model {MODEL_LOAD_PATH}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JhaUb-c9RGuG",
        "outputId": "cc0e86ef-fa93-453b-a6b6-4ae35dc4c7db"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "DCN not currently available. Ensure --dla_node 'conv' is being used.\n",
            "Fix size testing.\n",
            "training chunk_sizes: [32]\n",
            "Initializing visualizer...\n",
            "input h w: 448 800\n",
            "heads {'hm': 10, 'reg': 2, 'wh': 2, 'dep': 1, 'rot': 8, 'dim': 3, 'amodel_offset': 2, 'dep_sec': 1, 'rot_sec': 8, 'nuscenes_att': 8, 'velocity': 3}\n",
            "weights {'hm': 1, 'reg': 1, 'wh': 0.1, 'dep': 1, 'rot': 1, 'dim': 1, 'amodel_offset': 1, 'dep_sec': 1, 'rot_sec': 1, 'nuscenes_att': 1, 'velocity': 1}\n",
            "head conv {'hm': [256], 'reg': [256], 'wh': [256], 'dep': [256], 'rot': [256], 'dim': [256], 'amodel_offset': [256], 'dep_sec': [256, 256, 256], 'rot_sec': [256, 256, 256], 'nuscenes_att': [256, 256, 256], 'velocity': [256, 256, 256]}\n",
            "Loading dataset split: mini_val\n",
            "Dataset version \n",
            "==> initializing mini_val data from /content/CenterFusionModern/src/lib/../../data/nuscenes/annotations_6sweeps/mini_val.json, \n",
            " images from /content/CenterFusionModern/src/lib/../../data/nuscenes ...\n",
            "loading annotations into memory...\n",
            "Done (t=1.11s)\n",
            "creating index...\n",
            "index created!\n",
            "Loaded mini_val 486 samples\n",
            "Loading model and detector...\n",
            "Creating model...\n",
            "Using node type: (<class 'lib.model.networks.dla.Conv'>, <class 'lib.model.networks.dla.Conv'>)\n",
            "Warning: No ImageNet pretrain!!\n",
            "loaded /content/drive/MyDrive/CenterFusionModern/fusion_e10.pth, epoch 10\n",
            "Drop parameter base.fc.weight.\n",
            "Drop parameter base.fc.bias.\n",
            "--- Processing Sample 20 ---\n",
            "Running model inference...\n",
            "Post-processing detections...\n",
            "Drawing bounding boxes...\n",
            "Inference complete.\n",
            "\n",
            "Successfully saved visualization to:\n",
            "/content/sample_20_vis.jpg\n"
          ]
        }
      ],
      "source": [
        "# run the visualizer to show the model output for a given image\n",
        "!cd /content/CenterFusionModern/src && \\\n",
        "python3 visualizer.py ddd \\\n",
        "    --load_model {MODEL_LOAD_PATH} \\\n",
        "    --arch dla_34 \\\n",
        "    --dla_node 'conv' \\\n",
        "    --val_split mini_val \\\n",
        "    --pointcloud \\\n",
        "    --radar_sweeps 6 \\\n",
        "    --nuscenes_att \\\n",
        "    --velocity \\\n",
        "    --sample_id 20 \\\n",
        "    --save_path /content/sample_20_vis.jpg"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "p7PgBjhoZzMG"
      },
      "outputs": [],
      "source": [
        "# save the generated image to drive\n",
        "!cp /content/sample_20_vis.jpg /content/drive/MyDrive/CenterFusionModern"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K1syCYZKNqAb"
      },
      "source": [
        "#Camera Only Model\n",
        "Use this model for generating a camera only baseline. Be careful to not overwrite a previous model -- the model name will be saved as `model_{num_epochs}.pth` regardless of if camera only or camera radar fusion is used.\n",
        "\n",
        "It is recommended to save the model to drive and rename it to an identifiable name such as `camera_only_e20.pth`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5Xp3atCbjSPf",
        "outputId": "dcf8fa11-dcce-4fa2-9302-546f139561c6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Using mini nuScenes dataset only\n",
            "Using NUM_SWEEPS = 0\n",
            "======\n",
            "Loading NuScenes tables for version v1.0-mini...\n",
            "23 category,\n",
            "8 attribute,\n",
            "4 visibility,\n",
            "911 instance,\n",
            "12 sensor,\n",
            "120 calibrated_sensor,\n",
            "31206 ego_pose,\n",
            "8 log,\n",
            "10 scene,\n",
            "404 sample,\n",
            "31206 sample_data,\n",
            "18538 sample_annotation,\n",
            "4 map,\n",
            "Done loading in 0.379 seconds.\n",
            "======\n",
            "Reverse indexing ...\n",
            "Done reverse indexing in 0.1 seconds.\n",
            "======\n",
            "scene_name scene-0103\n",
            "scene_name scene-0916\n",
            "reordering images\n",
            "mini_val 486 images 4910 boxes\n",
            "out_path ../data/nuscenes/annotations/mini_val.json\n",
            "======\n",
            "Loading NuScenes tables for version v1.0-mini...\n",
            "23 category,\n",
            "8 attribute,\n",
            "4 visibility,\n",
            "911 instance,\n",
            "12 sensor,\n",
            "120 calibrated_sensor,\n",
            "31206 ego_pose,\n",
            "8 log,\n",
            "10 scene,\n",
            "404 sample,\n",
            "31206 sample_data,\n",
            "18538 sample_annotation,\n",
            "4 map,\n",
            "Done loading in 0.363 seconds.\n",
            "======\n",
            "Reverse indexing ...\n",
            "Done reverse indexing in 0.1 seconds.\n",
            "======\n",
            "scene_name scene-0061\n",
            "scene_name scene-0553\n",
            "scene_name scene-0655\n",
            "scene_name scene-0757\n",
            "scene_name scene-0796\n",
            "scene_name scene-1077\n",
            "scene_name scene-1094\n",
            "scene_name scene-1100\n",
            "reordering images\n",
            "mini_train 1938 images 14694 boxes\n",
            "out_path ../data/nuscenes/annotations/mini_train.json\n"
          ]
        }
      ],
      "source": [
        "# convert nuscenes dataset\n",
        "!cd \"{CF_ROOT}/src\" && \\\n",
        "python3 convert_nuScenes.py --radar_sweeps 0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "A2TyJ9TknMVQ"
      },
      "outputs": [],
      "source": [
        "# define useful parameters to be used between cells\n",
        "# this is helpful if we are only testing a model, only training, only visualizing\n",
        "# or any combination -- consistency is key\n",
        "\n",
        "# number of epochs to train model\n",
        "# if resuming, this should be the total number of epochs you want to train to\n",
        "NUM_EPOCHS = 20\n",
        "\n",
        "# model save paths\n",
        "EXPERIMENT_ID = \"centerfusion_camera_only\"\n",
        "MODEL_SAVE_NAME = f\"model_{NUM_EPOCHS}.pth\" # DO NOT CHANGE --(changing this does not change the actual save name, it's hard-coded to match this)\n",
        "MODEL_SAVE_PATH = f\"{CF_ROOT}/exp/ddd/{EXPERIMENT_ID}/{MODEL_SAVE_NAME}\"\n",
        "DRIVE_CF_DIR_PATH = \"/content/drive/MyDrive/CenterFusionModern\"\n",
        "\n",
        "# model load path, this is the path to the model you are evaluating\n",
        "# will also resume from model load path\n",
        "MODEL_LOAD_PATH = MODEL_SAVE_PATH\n",
        "RESUME_TRAINING = True # use if testing a pretrained model as well\n",
        "if RESUME_TRAINING:\n",
        "    MODEL_LOAD_PATH = f\"{DRIVE_CF_DIR_PATH}/camera_only_e20.pth\"\n",
        "\n",
        "# scale up the defaults to utilize the A100 at max potential\n",
        "# learning rate should scale with batch size\n",
        "BATCH_SIZE = 8 * 4\n",
        "LEARNING_RATE = 2.5e-4 * 4"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vq8dtndb9pib",
        "outputId": "f5ff0399-68e7-4ad6-84c7-1ef75faa3b0d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "DCN not currently available. Ensure --dla_node 'conv' is being used.\n",
            "Fix size testing.\n",
            "training chunk_sizes: [32]\n",
            "input h w: 448 800\n",
            "heads {'hm': 10, 'reg': 2, 'wh': 2, 'dep': 1, 'rot': 8, 'dim': 3, 'amodel_offset': 2, 'nuscenes_att': 8, 'velocity': 3}\n",
            "weights {'hm': 1, 'reg': 1, 'wh': 0.1, 'dep': 1, 'rot': 1, 'dim': 1, 'amodel_offset': 1, 'nuscenes_att': 1, 'velocity': 1}\n",
            "head conv {'hm': [256], 'reg': [256], 'wh': [256], 'dep': [256], 'rot': [256], 'dim': [256], 'amodel_offset': [256], 'nuscenes_att': [256], 'velocity': [256]}\n",
            "Options = Namespace(task='ddd', dataset='nuscenes', test_dataset='nuscenes', exp_id='centerfusion_camera_only', eval=False, debug=0, no_pause=False, demo='', load_model='', resume=False, gpus=[0], num_workers=4, not_cuda_benchmark=False, seed=317, not_set_cuda_env=False, print_iter=0, save_all=False, vis_thresh=0.3, debugger_theme='white', run_dataset_eval=False, save_imgs=[], save_img_suffix='', skip_first=-1, save_video=False, save_framerate=30, resize_video=False, video_h=512, video_w=512, transpose_video=False, show_track_color=False, not_show_bbox=False, not_show_number=False, qualitative=False, tango_color=False, arch='dla_34', dla_node='conv', head_conv={'hm': [256], 'reg': [256], 'wh': [256], 'dep': [256], 'rot': [256], 'dim': [256], 'amodel_offset': [256], 'nuscenes_att': [256], 'velocity': [256]}, num_head_conv=1, head_kernel=3, down_ratio=4, num_classes=10, num_resnet_layers=101, backbone='dla34', neck='dlaup', msra_outchannel=256, prior_bias=-4.6, input_res=800, input_h=448, input_w=800, dataset_version='', optim='adam', lr=0.001, lr_step=[50], save_point=[10, 20], num_epochs=20, batch_size=32, master_batch_size=32, num_iters=-1, val_intervals=5, trainval=False, ltrb=False, ltrb_weight=0.1, reset_hm=False, reuse_hm=False, dense_reg=1, shuffle_train=True, flip_test=False, test_scales=[1.0], nms=False, K=100, not_prefetch_test=False, fix_short=-1, keep_res=False, out_thresh=-1, depth_scale=1, save_results=False, load_results='', use_loaded_results=False, ignore_loaded_cats=[], model_output_list=False, non_block_test=False, vis_gt_bev='', kitti_split='3dop', test_focal_length=-1, not_rand_crop=True, not_max_crop=False, shift=0.1, scale=0, aug_rot=0, rotate=0, flip=0.5, no_color_aug=False, tracking=False, pre_hm=False, same_aug_pre=False, zero_pre_hm=False, hm_disturb=0, lost_disturb=0, fp_disturb=0, pre_thresh=-1, track_thresh=0.3, new_thresh=0.3, max_frame_dist=3, ltrb_amodal=False, ltrb_amodal_weight=0.1, public_det=False, no_pre_img=False, zero_tracking=False, hungarian=False, max_age=-1, tracking_weight=1, reg_loss='l1', hm_weight=1, off_weight=1, wh_weight=0.1, hp_weight=1, hm_hp_weight=1, amodel_offset_weight=1, dep_weight=1, dep_res_weight=1, dim_weight=1, rot_weight=1, nuscenes_att=True, nuscenes_att_weight=1, velocity=True, velocity_weight=1, custom_dataset_img_path='', custom_dataset_ann_path='', pointcloud=False, train_split='mini_train', val_split='mini_val', max_pc=1000, r_a=250, r_b=5, img_format='jpg', max_pc_dist=100.0, freeze_backbone=False, radar_sweeps=1, warm_start_weights=False, pc_z_offset=0, eval_n_plots=0, eval_render_curves=False, hm_transparency=0.7, iou_thresh=0, pillar_dims=[2.0, 0.5, 0.5], show_velocity=False, gpus_str='0', pre_img=False, fix_res=True, pad=31, num_stacks=1, chunk_sizes=[32], root_dir='/content/CenterFusionModern/src/lib/../..', data_dir='/content/CenterFusionModern/src/lib/../../data', exp_dir='/content/CenterFusionModern/src/lib/../../exp/ddd', save_dir='/content/CenterFusionModern/src/lib/../../exp/ddd/centerfusion_camera_only', debug_dir='/content/CenterFusionModern/src/lib/../../exp/ddd/centerfusion_camera_only/debug', pc_atts=['x', 'y', 'z', 'dyn_prop', 'id', 'rcs', 'vx', 'vy', 'vx_comp', 'vy_comp', 'is_quality_valid', 'ambig_state', 'x_rms', 'y_rms', 'invalid_state', 'pdh0', 'vx_rms', 'vy_rms'], num_img_channels=3, hm_dist_thresh=None, sigmoid_dep_sec=False, hm_to_box_ratio=0.3, secondary_heads=[], custom_head_convs={}, normalize_depth=False, disable_frustum=False, layers_to_freeze=['base', 'dla_up', 'ida_up'], output_h=112, output_w=200, output_res=200, heads={'hm': 10, 'reg': 2, 'wh': 2, 'dep': 1, 'rot': 8, 'dim': 3, 'amodel_offset': 2, 'nuscenes_att': 8, 'velocity': 3}, weights={'hm': 1, 'reg': 1, 'wh': 0.1, 'dep': 1, 'rot': 1, 'dim': 1, 'amodel_offset': 1, 'nuscenes_att': 1, 'velocity': 1})\n",
            "Creating model...\n",
            "Using node type: (<class 'lib.model.networks.dla.Conv'>, <class 'lib.model.networks.dla.Conv'>)\n",
            "Setting up validation data...\n",
            "Dataset version \n",
            "==> initializing mini_val data from /content/CenterFusionModern/src/lib/../../data/nuscenes/annotations/mini_val.json, \n",
            " images from /content/CenterFusionModern/src/lib/../../data/nuscenes ...\n",
            "loading annotations into memory...\n",
            "Done (t=0.09s)\n",
            "creating index...\n",
            "index created!\n",
            "Loaded mini_val 486 samples\n",
            "Setting up train data...\n",
            "Dataset version \n",
            "==> initializing mini_train data from /content/CenterFusionModern/src/lib/../../data/nuscenes/annotations/mini_train.json, \n",
            " images from /content/CenterFusionModern/src/lib/../../data/nuscenes ...\n",
            "loading annotations into memory...\n",
            "Done (t=0.27s)\n",
            "creating index...\n",
            "index created!\n",
            "Loaded mini_train 1938 samples\n",
            "Starting training...\n",
            "ddd/centerfusion_camera_only |################################| train: [1][59/60]|Tot: 0:00:38 |ETA: 0:00:01 |tot 26.0745 |hm 3.3792 |wh 10.1702 |reg 0.2693 |dep 14.4620 |dim 1.1314 |rot 2.0726 |amodel_offset 2.3508 |nuscenes_att 0.5487 |velocity 0.8436 |Data 0.261s(0.292s) |Net 0.634s\n",
            "ddd/centerfusion_camera_only |################################| train: [2][59/60]|Tot: 0:00:28 |ETA: 0:00:01 |tot 18.8926 |hm 2.7422 |wh 7.4480 |reg 0.2537 |dep 8.7766 |dim 0.8253 |rot 2.0024 |amodel_offset 2.2333 |nuscenes_att 0.5162 |velocity 0.7982 |Data 0.261s(0.285s) |Net 0.472s\n",
            "ddd/centerfusion_camera_only |################################| train: [3][59/60]|Tot: 0:00:28 |ETA: 0:00:01 |tot 19.5138 |hm 2.6340 |wh 6.7492 |reg 0.2532 |dep 9.5542 |dim 0.7692 |rot 1.9726 |amodel_offset 2.3350 |nuscenes_att 0.4996 |velocity 0.8211 |Data 0.261s(0.285s) |Net 0.472s \n",
            "ddd/centerfusion_camera_only |################################| train: [4][59/60]|Tot: 0:00:28 |ETA: 0:00:01 |tot 16.4321 |hm 2.4077 |wh 5.9705 |reg 0.2496 |dep 6.9367 |dim 0.6599 |rot 1.9161 |amodel_offset 2.3517 |nuscenes_att 0.4858 |velocity 0.8277 |Data 0.261s(0.285s) |Net 0.474s\n",
            "ddd/centerfusion_camera_only |################################| train: [5][59/60]|Tot: 0:00:28 |ETA: 0:00:01 |tot 15.1752 |hm 2.2234 |wh 5.3958 |reg 0.2465 |dep 6.1883 |dim 0.5905 |rot 1.8747 |amodel_offset 2.2442 |nuscenes_att 0.4629 |velocity 0.8051 |Data 0.262s(0.287s) |Net 0.473s\n",
            "ddd/centerfusion_camera_only |################################| val: [5][485/486]|Tot: 0:00:17 |ETA: 0:00:01 |tot 16.8661 |hm 2.6966 |wh 8.3227 |reg 0.2418 |dep 6.8863 |dim 0.5853 |rot 1.9695 |amodel_offset 2.9116 |nuscenes_att 0.4762 |velocity 0.2665 |Data 0.016s(0.018s) |Net 0.036s\n",
            "ddd/centerfusion_camera_only |################################| train: [6][59/60]|Tot: 0:00:28 |ETA: 0:00:01 |tot 15.4117 |hm 2.1691 |wh 5.0967 |reg 0.2484 |dep 6.6550 |dim 0.5614 |rot 1.8289 |amodel_offset 2.1890 |nuscenes_att 0.4424 |velocity 0.8079 |Data 0.261s(0.285s) |Net 0.473s\n",
            "ddd/centerfusion_camera_only |################################| train: [7][59/60]|Tot: 0:00:28 |ETA: 0:00:01 |tot 14.0393 |hm 2.0909 |wh 4.8710 |reg 0.2482 |dep 5.5100 |dim 0.5253 |rot 1.7729 |amodel_offset 2.1865 |nuscenes_att 0.4189 |velocity 0.7996 |Data 0.261s(0.282s) |Net 0.469s\n",
            "ddd/centerfusion_camera_only |################################| train: [8][59/60]|Tot: 0:00:28 |ETA: 0:00:01 |tot 14.4851 |hm 2.0687 |wh 4.6784 |reg 0.2467 |dep 6.0838 |dim 0.5070 |rot 1.7321 |amodel_offset 2.1774 |nuscenes_att 0.3923 |velocity 0.8093 |Data 0.261s(0.286s) |Net 0.474s\n",
            "ddd/centerfusion_camera_only |################################| train: [9][59/60]|Tot: 0:00:28 |ETA: 0:00:01 |tot 13.5957 |hm 1.9886 |wh 4.6673 |reg 0.2456 |dep 5.4344 |dim 0.4794 |rot 1.6697 |amodel_offset 2.1299 |nuscenes_att 0.3737 |velocity 0.8077 |Data 0.262s(0.282s) |Net 0.475s\n",
            "ddd/centerfusion_camera_only |################################| train: [10][59/60]|Tot: 0:00:28 |ETA: 0:00:01 |tot 13.2591 |hm 1.9408 |wh 4.4336 |reg 0.2431 |dep 5.1999 |dim 0.4723 |rot 1.6125 |amodel_offset 2.1702 |nuscenes_att 0.3621 |velocity 0.8149 |Data 0.261s(0.285s) |Net 0.473s\n",
            "ddd/centerfusion_camera_only |################################| val: [10][485/486]|Tot: 0:00:16 |ETA: 0:00:01 |tot 14.7605 |hm 2.5220 |wh 6.8289 |reg 0.2411 |dep 5.0695 |dim 0.5220 |rot 1.9968 |amodel_offset 2.8728 |nuscenes_att 0.5881 |velocity 0.2653 |Data 0.015s(0.019s) |Net 0.033s\n",
            "ddd/centerfusion_camera_only |################################| train: [11][59/60]|Tot: 0:00:28 |ETA: 0:00:01 |tot 13.0179 |hm 1.8854 |wh 4.2941 |reg 0.2453 |dep 5.1495 |dim 0.4480 |rot 1.5725 |amodel_offset 2.1469 |nuscenes_att 0.3413 |velocity 0.7996 |Data 0.261s(0.283s) |Net 0.471s\n",
            "ddd/centerfusion_camera_only |################################| train: [12][59/60]|Tot: 0:00:28 |ETA: 0:00:01 |tot 12.4882 |hm 1.8606 |wh 4.1635 |reg 0.2462 |dep 4.8091 |dim 0.4376 |rot 1.5174 |amodel_offset 2.0760 |nuscenes_att 0.3261 |velocity 0.7988 |Data 0.261s(0.287s) |Net 0.474s\n",
            "ddd/centerfusion_camera_only |################################| train: [13][59/60]|Tot: 0:00:28 |ETA: 0:00:01 |tot 11.8885 |hm 1.8420 |wh 4.0488 |reg 0.2432 |dep 4.3440 |dim 0.4217 |rot 1.4772 |amodel_offset 2.0395 |nuscenes_att 0.3125 |velocity 0.8035 |Data 0.260s(0.287s) |Net 0.474s\n",
            "ddd/centerfusion_camera_only |################################| train: [14][59/60]|Tot: 0:00:28 |ETA: 0:00:01 |tot 11.8751 |hm 1.8082 |wh 4.0788 |reg 0.2425 |dep 4.4317 |dim 0.4091 |rot 1.4410 |amodel_offset 2.0274 |nuscenes_att 0.2980 |velocity 0.8093 |Data 0.261s(0.287s) |Net 0.475s\n",
            "ddd/centerfusion_camera_only |################################| train: [15][59/60]|Tot: 0:00:28 |ETA: 0:00:01 |tot 11.5966 |hm 1.7920 |wh 3.8495 |reg 0.2413 |dep 4.4231 |dim 0.4005 |rot 1.4115 |amodel_offset 1.8561 |nuscenes_att 0.2898 |velocity 0.7974 |Data 0.261s(0.286s) |Net 0.472s\n",
            "ddd/centerfusion_camera_only |################################| val: [15][485/486]|Tot: 0:00:15 |ETA: 0:00:01 |tot 15.5785 |hm 2.4863 |wh 6.8686 |reg 0.2411 |dep 6.0787 |dim 0.5321 |rot 2.0867 |amodel_offset 2.6274 |nuscenes_att 0.5648 |velocity 0.2745 |Data 0.015s(0.018s) |Net 0.032s\n",
            "ddd/centerfusion_camera_only |################################| train: [16][59/60]|Tot: 0:00:28 |ETA: 0:00:01 |tot 11.7738 |hm 1.7815 |wh 3.9901 |reg 0.2413 |dep 4.6000 |dim 0.3995 |rot 1.4236 |amodel_offset 1.8452 |nuscenes_att 0.2992 |velocity 0.7845 |Data 0.261s(0.285s) |Net 0.472s\n",
            "ddd/centerfusion_camera_only |################################| train: [17][59/60]|Tot: 0:00:28 |ETA: 0:00:01 |tot 10.6587 |hm 1.7094 |wh 3.6844 |reg 0.2392 |dep 3.8387 |dim 0.3755 |rot 1.3646 |amodel_offset 1.7462 |nuscenes_att 0.2658 |velocity 0.7508 |Data 0.262s(0.284s) |Net 0.471s\n",
            "ddd/centerfusion_camera_only |################################| train: [18][59/60]|Tot: 0:00:28 |ETA: 0:00:01 |tot 10.8148 |hm 1.7139 |wh 3.7354 |reg 0.2385 |dep 4.0973 |dim 0.3763 |rot 1.3194 |amodel_offset 1.6932 |nuscenes_att 0.2692 |velocity 0.7334 |Data 0.261s(0.287s) |Net 0.474s\n",
            "ddd/centerfusion_camera_only |################################| train: [19][59/60]|Tot: 0:00:28 |ETA: 0:00:01 |tot 12.0396 |hm 1.7386 |wh 3.7680 |reg 0.2384 |dep 5.3399 |dim 0.3864 |rot 1.3753 |amodel_offset 1.6028 |nuscenes_att 0.2696 |velocity 0.7118 |Data 0.261s(0.285s) |Net 0.471s\n",
            "ddd/centerfusion_camera_only |################################| train: [20][59/60]|Tot: 0:00:28 |ETA: 0:00:01 |tot 10.6334 |hm 1.7163 |wh 3.7573 |reg 0.2377 |dep 4.1401 |dim 0.3740 |rot 1.3333 |amodel_offset 1.5261 |nuscenes_att 0.2485 |velocity 0.6815 |Data 0.261s(0.288s) |Net 0.474s\n",
            "ddd/centerfusion_camera_only |################################| val: [20][485/486]|Tot: 0:00:15 |ETA: 0:00:01 |tot 14.0830 |hm 2.5142 |wh 6.7492 |reg 0.2401 |dep 5.0010 |dim 0.4798 |rot 2.0370 |amodel_offset 2.3373 |nuscenes_att 0.5006 |velocity 0.2981 |Data 0.015s(0.017s) |Net 0.032s\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "# train camera-only model for comparison\n",
        "!export CUDA_VISIBLE_DEVICES=0\n",
        "\n",
        "# train for single gpu\n",
        "if not RESUME_TRAINING:\n",
        "    !cd /content/CenterFusionModern/src && \\\n",
        "    python3 main.py \\\n",
        "        ddd \\\n",
        "        --exp_id {EXPERIMENT_ID} \\\n",
        "        --arch dla_34 \\\n",
        "        --dla_node 'conv' \\\n",
        "        --shuffle_train \\\n",
        "        --train_split mini_train \\\n",
        "        --val_split mini_val \\\n",
        "        --val_intervals 5 \\\n",
        "        --nuscenes_att \\\n",
        "        --velocity \\\n",
        "        --batch_size {BATCH_SIZE} \\\n",
        "        --lr {LEARNING_RATE} \\\n",
        "        --num_epochs {NUM_EPOCHS} \\\n",
        "        --lr_step 50 \\\n",
        "        --save_point {NUM_EPOCHS // 2},{NUM_EPOCHS} \\\n",
        "        --gpus 0 \\\n",
        "        --not_rand_crop \\\n",
        "        --flip 0.5 \\\n",
        "        --shift 0.1 \\\n",
        "        --print_iter 0\n",
        "else: # resuming training\n",
        "    !cd /content/CenterFusionModern/src && \\\n",
        "    python3 main.py \\\n",
        "        ddd \\\n",
        "        --exp_id {EXPERIMENT_ID} \\\n",
        "        --arch dla_34 \\\n",
        "        --dla_node 'conv' \\\n",
        "        --shuffle_train \\\n",
        "        --train_split mini_train \\\n",
        "        --val_split mini_val \\\n",
        "        --val_intervals 5 \\\n",
        "        --nuscenes_att \\\n",
        "        --velocity \\\n",
        "        --batch_size {BATCH_SIZE} \\\n",
        "        --lr {LEARNING_RATE} \\\n",
        "        --num_epochs {NUM_EPOCHS} \\\n",
        "        --lr_step 50 \\\n",
        "        --save_point {NUM_EPOCHS // 2},{NUM_EPOCHS} \\\n",
        "        --gpus 0 \\\n",
        "        --not_rand_crop \\\n",
        "        --flip 0.5 \\\n",
        "        --shift 0.1 \\\n",
        "        --print_iter 0 \\\n",
        "        --resume"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e5f6MvfgfNNE",
        "outputId": "aac46d27-aa86-43e6-d4e6-24f4a62b1ddc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Copied /content/CenterFusionModern/exp/ddd/centerfusion_camera_only/model_20.pth to /content/drive/MyDrive/CenterFusionModern successfully.\n"
          ]
        }
      ],
      "source": [
        "# export a copy of fusion model to drive\n",
        "# ensure path is correct, model name is \"model_{num-epochs}\"\n",
        "!cp {MODEL_SAVE_PATH} {DRIVE_CF_DIR_PATH}\n",
        "print(f\"Copied {MODEL_SAVE_PATH} to {DRIVE_CF_DIR_PATH} successfully.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3i1IKgBVMcB3",
        "outputId": "bcca04c2-59df-4a39-c86a-41df0c081a61"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "DCN not currently available. Ensure --dla_node 'conv' is being used.\n",
            "Fix size testing.\n",
            "training chunk_sizes: [32]\n",
            "input h w: 448 800\n",
            "heads {'hm': 10, 'reg': 2, 'wh': 2, 'dep': 1, 'rot': 8, 'dim': 3, 'amodel_offset': 2, 'nuscenes_att': 8, 'velocity': 3}\n",
            "weights {'hm': 1, 'reg': 1, 'wh': 0.1, 'dep': 1, 'rot': 1, 'dim': 1, 'amodel_offset': 1, 'nuscenes_att': 1, 'velocity': 1}\n",
            "head conv {'hm': [256], 'reg': [256], 'wh': [256], 'dep': [256], 'rot': [256], 'dim': [256], 'amodel_offset': [256], 'nuscenes_att': [256], 'velocity': [256]}\n",
            "Namespace(task='ddd', dataset='nuscenes', test_dataset='nuscenes', exp_id='centerfusion', eval=False, debug=0, no_pause=False, demo='', load_model='/content/drive/MyDrive/CenterFusionModern/camera_only_e20.pth', resume=False, gpus=[0], num_workers=4, not_cuda_benchmark=False, seed=317, not_set_cuda_env=False, print_iter=0, save_all=False, vis_thresh=0.3, debugger_theme='white', run_dataset_eval=True, save_imgs=[], save_img_suffix='', skip_first=-1, save_video=False, save_framerate=30, resize_video=False, video_h=512, video_w=512, transpose_video=False, show_track_color=False, not_show_bbox=False, not_show_number=False, qualitative=False, tango_color=False, arch='dla_34', dla_node='conv', head_conv={'hm': [256], 'reg': [256], 'wh': [256], 'dep': [256], 'rot': [256], 'dim': [256], 'amodel_offset': [256], 'nuscenes_att': [256], 'velocity': [256]}, num_head_conv=1, head_kernel=3, down_ratio=4, num_classes=10, num_resnet_layers=101, backbone='dla34', neck='dlaup', msra_outchannel=256, prior_bias=-4.6, input_res=800, input_h=448, input_w=800, dataset_version='', optim='adam', lr=0.000125, lr_step=[60], save_point=[90], num_epochs=70, batch_size=32, master_batch_size=32, num_iters=-1, val_intervals=10, trainval=False, ltrb=False, ltrb_weight=0.1, reset_hm=False, reuse_hm=False, dense_reg=1, shuffle_train=False, flip_test=False, test_scales=[1.0], nms=False, K=100, not_prefetch_test=False, fix_short=-1, keep_res=False, out_thresh=-1, depth_scale=1, save_results=False, load_results='', use_loaded_results=False, ignore_loaded_cats=[], model_output_list=False, non_block_test=False, vis_gt_bev='', kitti_split='3dop', test_focal_length=-1, not_rand_crop=False, not_max_crop=False, shift=0, scale=0, aug_rot=0, rotate=0, flip=0.5, no_color_aug=False, tracking=False, pre_hm=False, same_aug_pre=False, zero_pre_hm=False, hm_disturb=0, lost_disturb=0, fp_disturb=0, pre_thresh=-1, track_thresh=0.3, new_thresh=0.3, max_frame_dist=3, ltrb_amodal=False, ltrb_amodal_weight=0.1, public_det=False, no_pre_img=False, zero_tracking=False, hungarian=False, max_age=-1, tracking_weight=1, reg_loss='l1', hm_weight=1, off_weight=1, wh_weight=0.1, hp_weight=1, hm_hp_weight=1, amodel_offset_weight=1, dep_weight=1, dep_res_weight=1, dim_weight=1, rot_weight=1, nuscenes_att=True, nuscenes_att_weight=1, velocity=True, velocity_weight=1, custom_dataset_img_path='', custom_dataset_ann_path='', pointcloud=False, train_split='train', val_split='mini_val', max_pc=1000, r_a=250, r_b=5, img_format='jpg', max_pc_dist=100.0, freeze_backbone=False, radar_sweeps=1, warm_start_weights=False, pc_z_offset=0, eval_n_plots=0, eval_render_curves=False, hm_transparency=0.7, iou_thresh=0, pillar_dims=[2.0, 0.5, 0.5], show_velocity=False, gpus_str='0', pre_img=False, fix_res=True, pad=31, num_stacks=1, chunk_sizes=[32], root_dir='/content/CenterFusionModern/src/lib/../..', data_dir='/content/CenterFusionModern/src/lib/../../data', exp_dir='/content/CenterFusionModern/src/lib/../../exp/ddd', save_dir='/content/CenterFusionModern/src/lib/../../exp/ddd/centerfusion', debug_dir='/content/CenterFusionModern/src/lib/../../exp/ddd/centerfusion/debug', pc_atts=['x', 'y', 'z', 'dyn_prop', 'id', 'rcs', 'vx', 'vy', 'vx_comp', 'vy_comp', 'is_quality_valid', 'ambig_state', 'x_rms', 'y_rms', 'invalid_state', 'pdh0', 'vx_rms', 'vy_rms'], num_img_channels=3, hm_dist_thresh=None, sigmoid_dep_sec=False, hm_to_box_ratio=0.3, secondary_heads=[], custom_head_convs={}, normalize_depth=False, disable_frustum=False, layers_to_freeze=['base', 'dla_up', 'ida_up'], output_h=112, output_w=200, output_res=200, heads={'hm': 10, 'reg': 2, 'wh': 2, 'dep': 1, 'rot': 8, 'dim': 3, 'amodel_offset': 2, 'nuscenes_att': 8, 'velocity': 3}, weights={'hm': 1, 'reg': 1, 'wh': 0.1, 'dep': 1, 'rot': 1, 'dim': 1, 'amodel_offset': 1, 'nuscenes_att': 1, 'velocity': 1})\n",
            "Dataset version \n",
            "==> initializing mini_val data from /content/CenterFusionModern/src/lib/../../data/nuscenes/annotations/mini_val.json, \n",
            " images from /content/CenterFusionModern/src/lib/../../data/nuscenes ...\n",
            "loading annotations into memory...\n",
            "Done (t=0.09s)\n",
            "creating index...\n",
            "index created!\n",
            "Loaded mini_val 486 samples\n",
            "Creating model...\n",
            "Using node type: (<class 'lib.model.networks.dla.Conv'>, <class 'lib.model.networks.dla.Conv'>)\n",
            "Warning: No ImageNet pretrain!!\n",
            "loaded /content/drive/MyDrive/CenterFusionModern/camera_only_e20.pth, epoch 20\n",
            "Drop parameter base.fc.weight.\n",
            "Drop parameter base.fc.bias.\n",
            "centerfusion |################################| [485/486]|Tot: 0:00:19 |ETA: 0:00:01 |tot 0.025s (0.031s) |load 0.000s (0.000s) |pre 0.000s (0.000s) |net 0.012s (0.015s) |dec 0.002s (0.003s) |post 0.010s (0.012s) |merge 0.001s (0.001s) |track 0.000s (0.000s) \n",
            "Converting nuscenes format...\n",
            "======\n",
            "Loading NuScenes tables for version v1.0-mini...\n",
            "23 category,\n",
            "8 attribute,\n",
            "4 visibility,\n",
            "911 instance,\n",
            "12 sensor,\n",
            "120 calibrated_sensor,\n",
            "31206 ego_pose,\n",
            "8 log,\n",
            "10 scene,\n",
            "404 sample,\n",
            "31206 sample_data,\n",
            "18538 sample_annotation,\n",
            "4 map,\n",
            "Done loading in 0.392 seconds.\n",
            "======\n",
            "Reverse indexing ...\n",
            "Done reverse indexing in 0.1 seconds.\n",
            "======\n",
            "Initializing nuScenes detection evaluation\n",
            "Loaded results from /content/CenterFusionModern/src/lib/../../exp/ddd/centerfusion/results_nuscenes_det_mini_val.json. Found detections for 81 samples.\n",
            "Loading annotations for mini_val split from nuScenes version: v1.0-mini\n",
            "100% 81/81 [00:00<00:00, 385.80it/s]\n",
            "Loaded ground truth annotations for 81 samples.\n",
            "Filtering predictions\n",
            "=> Original number of boxes: 40500\n",
            "=> After distance based filtering: 35650\n",
            "=> After LIDAR and RADAR points based filtering: 35650\n",
            "=> After bike rack filtering: 35647\n",
            "Filtering ground truth annotations\n",
            "=> Original number of boxes: 4441\n",
            "=> After distance based filtering: 3785\n",
            "=> After LIDAR and RADAR points based filtering: 3393\n",
            "=> After bike rack filtering: 3393\n",
            "Accumulating metric data...\n",
            "Calculating metrics...\n",
            "Saving metrics to: /content/CenterFusionModern/src/lib/../../exp/ddd/centerfusion/nuscenes_eval_det_output_mini_val/\n",
            "mAP: 0.0349\n",
            "mATE: 1.0312\n",
            "mASE: 0.7465\n",
            "mAOE: 1.1138\n",
            "mAVE: 0.9127\n",
            "mAAE: 0.7376\n",
            "NDS: 0.0778\n",
            "Eval time: 8.3s\n",
            "\n",
            "Per-class results:\n",
            "Object Class        \tAP    \tATE   \tASE   \tAOE   \tAVE   \tAAE   \n",
            "car                 \t0.063 \t1.157 \t0.240 \t1.247 \t0.458 \t0.345 \n",
            "truck               \t0.000 \t1.242 \t0.349 \t1.482 \t0.930 \t0.258 \n",
            "bus                 \t0.000 \t1.000 \t1.000 \t1.000 \t1.000 \t1.000 \n",
            "trailer             \t0.000 \t1.000 \t1.000 \t1.000 \t1.000 \t1.000 \n",
            "construction_vehicle\t0.000 \t1.000 \t1.000 \t1.000 \t1.000 \t1.000 \n",
            "pedestrian          \t0.109 \t1.020 \t0.333 \t1.296 \t0.913 \t0.298 \n",
            "motorcycle          \t0.000 \t1.000 \t1.000 \t1.000 \t1.000 \t1.000 \n",
            "bicycle             \t0.000 \t1.000 \t1.000 \t1.000 \t1.000 \t1.000 \n",
            "traffic_cone        \t0.178 \t0.893 \t0.543 \tnan   \tnan   \tnan   \n",
            "barrier             \t0.000 \t1.000 \t1.000 \t1.000 \tnan   \tnan   \n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "# test model metrics -- camera only\n",
        "# set the GPU to be visible\n",
        "!export CUDA_VISIBLE_DEVICES=0\n",
        "\n",
        "# Navigate to the source directory\n",
        "# Run the evaluation script\n",
        "!cd /content/CenterFusionModern/src && \\\n",
        "python3 test.py ddd \\\n",
        "    --exp_id centerfusion \\\n",
        "    --arch dla_34 \\\n",
        "    --dla_node 'conv' \\\n",
        "    --dataset nuscenes \\\n",
        "    --nuscenes_att \\\n",
        "    --velocity \\\n",
        "    --val_split mini_val \\\n",
        "    --run_dataset_eval \\\n",
        "    --gpus 0 \\\n",
        "    --load_model {MODEL_LOAD_PATH}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OoGtpf01CLni"
      },
      "outputs": [],
      "source": [
        "# run the visualizer to show the model output for a given image\n",
        "!cd /content/CenterFusionModern/src && \\\n",
        "python3 visualizer.py ddd \\\n",
        "    --load_model {MODEL_LOAD_PATH} \\\n",
        "    --arch dla_34 \\\n",
        "    --dla_node 'conv' \\\n",
        "    --val_split mini_val \\\n",
        "    --nuscenes_att \\\n",
        "    --velocity \\\n",
        "    --sample_id 20 \\\n",
        "    --save_path /content/camera_only_id20.jpg"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vcpxA0_sCUah"
      },
      "outputs": [],
      "source": [
        "# save the generated image to drive\n",
        "!cp /content/camera_only_id20.jpg /content/drive/MyDrive/CenterFusionModern"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "A100",
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
